#!/usr/bin/env python3
"""
çµæ´»çš„è§†é¢‘è¿›åº¦æ¡å·¥å…· - æ ¸å¿ƒæ¨¡å—

æ”¯æŒä»»æ„GIFè§’è‰²ï¼Œå¯è°ƒæ•´æ‰€æœ‰è§†è§‰å‚æ•°
ä½œè€…: AI Assistant
ç‰ˆæœ¬: 1.0.0
"""

import cv2
import numpy as np
import os
import math
import json
from typing import Tuple, Optional, List, Dict, Any
from PIL import Image, ImageSequence
import tempfile

# ç”¨äºèµ„æºæ–‡ä»¶è·¯å¾„å¤„ç†
from importlib.resources import files

# moviepyä½œä¸ºå¿…éœ€ä¾èµ–
from moviepy import VideoFileClip, ImageSequenceClip

# è¿›åº¦æ˜¾ç¤º
from tqdm import tqdm

# æŠ‘åˆ¶OpenCVçš„FFmpegè­¦å‘Šä¿¡æ¯
os.environ['OPENCV_FFMPEG_CAPTURE_OPTIONS'] = 'protocol_whitelist;file,rtp,udp'

# å¸¸é‡å®šä¹‰
LIGHTNING_UPDATE_INTERVAL = 15  # ç”µå…‰ç‰¹æ•ˆæ›´æ–°é—´éš”ï¼ˆå¸§ï¼‰
PARTICLE_LIFE_DECAY = 1  # ç²’å­ç”Ÿå‘½å€¼é€’å‡
MAX_LIGHTNING_PARTICLES = 50  # æœ€å¤§ç”µå…‰ç²’å­æ•°é‡
MAX_TRAIL_PARTICLES = 100  # æœ€å¤§å°¾è¿¹ç²’å­æ•°é‡


class VideoProgressBar:
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        çµæ´»çš„è¿›åº¦æ¡é…ç½®

        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰å¯è°ƒæ•´çš„å‚æ•°ã€‚å¦‚æœä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤é…ç½®ã€‚

        Raises:
            ValueError: å½“é…ç½®å‚æ•°æ— æ•ˆæ—¶æŠ›å‡º
        """
        # å¦‚æœæ²¡æœ‰æä¾›é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        if config is None:
            config = {}

        # éªŒè¯é…ç½®å‚æ•°
        self._validate_config(config)
            
        # è¿›åº¦æ¡åŸºæœ¬é…ç½®
        self.bar_height = config.get('bar_height', 40)
        self.bar_color = tuple(config.get('bar_color', [0, 255, 255]))  # BGRæ ¼å¼
        self.background_color = tuple(config.get('background_color', [50, 50, 50]))
        self.position = config.get('position', 'bottom')  # top/bottom
        self.margin = config.get('margin', 25)
        
        # è§’è‰²é…ç½® - ä½¿ç”¨åŒ…å†…èµ„æºçš„ç›¸å¯¹è·¯å¾„
        default_character = self._get_default_character_path()
        self.character_path = config.get('character_path', default_character)
        self.character_size = tuple(config.get('character_size', [60, 60]))
        self.character_offset_x = config.get('character_offset_x', 0)  # è§’è‰²Xè½´åç§»
        self.character_offset_y = config.get('character_offset_y', -5)  # è§’è‰²Yè½´åç§»
        
        # åŠ¨ç”»é…ç½®
        self.enable_bounce = config.get('enable_bounce', True)
        self.bounce_amplitude = config.get('bounce_amplitude', 8)
        self.bounce_speed = config.get('bounce_speed', 0.2)
        self.animation_speed = config.get('animation_speed', 3)  # GIFå¸§åˆ‡æ¢é€Ÿåº¦
        
        # ç‰¹æ•ˆé…ç½®
        self.enable_lightning = config.get('enable_lightning', True)
        self.lightning_chance = config.get('lightning_chance', 0.3)  # ç”µå…‰è§¦å‘æ¦‚ç‡
        self.lightning_color = tuple(config.get('lightning_color', [0, 255, 255]))
        
        self.enable_particles = config.get('enable_particles', True)
        self.particle_color = tuple(config.get('particle_color', [0, 255, 255]))
        self.particle_lifetime = config.get('particle_lifetime', 60)
        
        # æ–‡å­—é…ç½®
        self.text_color = tuple(config.get('text_color', [0, 255, 255]))
        self.text_size = config.get('text_size', 0.8)
        self.text_position = config.get('text_position', 'right')  # left/right/center
        self.text_offset_x = config.get('text_offset_x', 15)
        self.text_offset_y = config.get('text_offset_y', 0)

        # å­—ä½“é…ç½®
        font_map = {
            'simplex': cv2.FONT_HERSHEY_SIMPLEX,
            'plain': cv2.FONT_HERSHEY_PLAIN,
            'duplex': cv2.FONT_HERSHEY_DUPLEX,
            'complex': cv2.FONT_HERSHEY_COMPLEX,
            'triplex': cv2.FONT_HERSHEY_TRIPLEX,
            'complex_small': cv2.FONT_HERSHEY_COMPLEX_SMALL,
            'script_simplex': cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,
            'script_complex': cv2.FONT_HERSHEY_SCRIPT_COMPLEX
        }
        font_name = config.get('text_font', 'simplex')
        self.text_font = font_map.get(font_name, cv2.FONT_HERSHEY_SIMPLEX)

        # æ–‡å­—æè¾¹é…ç½®
        self.text_outline = config.get('text_outline', True)
        self.text_outline_color = tuple(config.get('text_outline_color', [0, 0, 0]))
        self.text_outline_thickness = config.get('text_outline_thickness', 2)
        
        # è¿›åº¦æ¡æ ·å¼é…ç½®
        self.border_thickness = config.get('border_thickness', 3)
        self.border_color = tuple(config.get('border_color', [255, 255, 255]))
        self.gradient_enabled = config.get('gradient_enabled', True)
        self.glow_enabled = config.get('glow_enabled', True)

        # å¤šè‰²æ¸å˜é…ç½®
        self.gradient_type = config.get('gradient_type', 'multi')  # linear, multi
        self.gradient_colors = config.get('gradient_colors', [
            [0, 255, 255],    # èµ·å§‹è‰²ï¼ˆé’è‰²ï¼‰
            [0, 200, 255],    # ä¸­é—´è‰²
            [0, 150, 255]     # ç»“æŸè‰²ï¼ˆè“è‰²ï¼‰
        ])
        
        # å†…éƒ¨å˜é‡
        self.frame_count = 0
        self.character_frames = self._load_character()
        self.total_frames = len(self.character_frames)
        self.lightning_particles = []
        self.trail_particles = []

        # æ€§èƒ½ä¼˜åŒ–ï¼šé¢„è®¡ç®—æ¸å˜é¢œè‰²
        self._precompute_gradient_colors()

    def _validate_config(self, config: Dict[str, Any]) -> None:
        """
        éªŒè¯é…ç½®å‚æ•°çš„æœ‰æ•ˆæ€§

        Args:
            config: é…ç½®å­—å…¸

        Raises:
            ValueError: å½“é…ç½®å‚æ•°æ— æ•ˆæ—¶æŠ›å‡º
        """
        errors = []

        # éªŒè¯é¢œè‰²å€¼ (BGRæ ¼å¼ï¼Œæ¯ä¸ªåˆ†é‡0-255)
        color_keys = ['bar_color', 'background_color', 'text_color', 'particle_color',
                     'lightning_color', 'border_color', 'text_outline_color']
        for color_key in color_keys:
            if color_key in config:
                color = config[color_key]
                if not isinstance(color, (list, tuple)) or len(color) != 3:
                    errors.append(f"{color_key} å¿…é¡»æ˜¯åŒ…å«3ä¸ªå…ƒç´ çš„åˆ—è¡¨æˆ–å…ƒç»„ (BGRæ ¼å¼)")
                elif not all(isinstance(c, (int, float)) and 0 <= c <= 255 for c in color):
                    errors.append(f"{color_key} é¢œè‰²å€¼å¿…é¡»åœ¨0-255èŒƒå›´å†…")

        # éªŒè¯æ¸å˜é¢œè‰²
        if 'gradient_colors' in config:
            gradient_colors = config['gradient_colors']
            if not isinstance(gradient_colors, list) or len(gradient_colors) < 2:
                errors.append("gradient_colors å¿…é¡»æ˜¯åŒ…å«è‡³å°‘2ä¸ªé¢œè‰²çš„åˆ—è¡¨")
            else:
                for i, color in enumerate(gradient_colors):
                    if not isinstance(color, (list, tuple)) or len(color) != 3:
                        errors.append(f"gradient_colors[{i}] å¿…é¡»æ˜¯åŒ…å«3ä¸ªå…ƒç´ çš„åˆ—è¡¨æˆ–å…ƒç»„")
                    elif not all(isinstance(c, (int, float)) and 0 <= c <= 255 for c in color):
                        errors.append(f"gradient_colors[{i}] é¢œè‰²å€¼å¿…é¡»åœ¨0-255èŒƒå›´å†…")

        # éªŒè¯å°ºå¯¸å‚æ•°
        if 'character_size' in config:
            size = config['character_size']
            if not isinstance(size, (list, tuple)) or len(size) != 2:
                errors.append("character_size å¿…é¡»æ˜¯åŒ…å«2ä¸ªå…ƒç´ çš„åˆ—è¡¨æˆ–å…ƒç»„ [å®½, é«˜]")
            elif not all(isinstance(s, (int, float)) and 1 <= s <= 1000 for s in size):
                errors.append("character_size å°ºå¯¸å¿…é¡»åœ¨1-1000åƒç´ èŒƒå›´å†…")

        # éªŒè¯æ•°å€¼èŒƒå›´
        numeric_validations = {
            'bar_height': (1, 200, "è¿›åº¦æ¡é«˜åº¦å¿…é¡»åœ¨1-200åƒç´ èŒƒå›´å†…"),
            'margin': (0, 500, "è¾¹è·å¿…é¡»åœ¨0-500åƒç´ èŒƒå›´å†…"),
            'bounce_amplitude': (0, 100, "å¼¹è·³å¹…åº¦å¿…é¡»åœ¨0-100åƒç´ èŒƒå›´å†…"),
            'bounce_speed': (0.01, 2.0, "å¼¹è·³é€Ÿåº¦å¿…é¡»åœ¨0.01-2.0èŒƒå›´å†…"),
            'animation_speed': (1, 20, "åŠ¨ç”»é€Ÿåº¦å¿…é¡»åœ¨1-20èŒƒå›´å†…"),
            'lightning_chance': (0.0, 1.0, "ç”µå…‰æ¦‚ç‡å¿…é¡»åœ¨0.0-1.0èŒƒå›´å†…"),
            'particle_lifetime': (1, 300, "ç²’å­ç”Ÿå‘½å‘¨æœŸå¿…é¡»åœ¨1-300å¸§èŒƒå›´å†…"),
            'text_size': (0.1, 5.0, "æ–‡å­—å¤§å°å¿…é¡»åœ¨0.1-5.0èŒƒå›´å†…"),
            'border_thickness': (0, 20, "è¾¹æ¡†åšåº¦å¿…é¡»åœ¨0-20åƒç´ èŒƒå›´å†…"),
            'text_outline_thickness': (0, 10, "æ–‡å­—æè¾¹åšåº¦å¿…é¡»åœ¨0-10åƒç´ èŒƒå›´å†…")
        }

        for key, (min_val, max_val, error_msg) in numeric_validations.items():
            if key in config:
                value = config[key]
                if not isinstance(value, (int, float)) or not (min_val <= value <= max_val):
                    errors.append(error_msg)

        # éªŒè¯æšä¸¾å€¼
        if 'position' in config and config['position'] not in ['top', 'bottom']:
            errors.append("position å¿…é¡»æ˜¯ 'top' æˆ– 'bottom'")

        if 'text_position' in config and config['text_position'] not in ['left', 'center', 'right', 'follow']:
            errors.append("text_position å¿…é¡»æ˜¯ 'left', 'center', 'right' æˆ– 'follow'")

        if 'gradient_type' in config and config['gradient_type'] not in ['linear', 'multi']:
            errors.append("gradient_type å¿…é¡»æ˜¯ 'linear' æˆ– 'multi'")

        # éªŒè¯æ–‡ä»¶è·¯å¾„
        if 'character_path' in config:
            char_path = config['character_path']
            if char_path is not None:  # å…è®¸Noneå€¼ï¼Œè¡¨ç¤ºä½¿ç”¨é»˜è®¤è§’è‰²
                if not isinstance(char_path, str):
                    errors.append("character_path å¿…é¡»æ˜¯å­—ç¬¦ä¸²æˆ–None")
                elif char_path != "default" and not char_path.lower().endswith('.gif'):
                    errors.append("character_path å¿…é¡»æ˜¯GIFæ–‡ä»¶æˆ–'default'")

        if errors:
            raise ValueError("é…ç½®éªŒè¯å¤±è´¥:\n" + "\n".join(f"  - {error}" for error in errors))

    def _precompute_gradient_colors(self) -> None:
        """é¢„è®¡ç®—æ¸å˜é¢œè‰²è¡¨ï¼Œæé«˜æ€§èƒ½"""
        if not self.gradient_enabled or self.gradient_type != 'multi':
            self.gradient_color_cache = {}
            return

        self.gradient_color_cache = {}
        # é¢„è®¡ç®—256ä¸ªé¢œè‰²ç‚¹
        for i in range(256):
            ratio = i / 255.0
            self.gradient_color_cache[i] = self._calculate_gradient_color(ratio)

    def _calculate_gradient_color(self, ratio: float) -> tuple:
        """è®¡ç®—æ¸å˜é¢œè‰²ï¼ˆç”¨äºé¢„è®¡ç®—ï¼‰"""
        if not self.gradient_colors or len(self.gradient_colors) < 2:
            return self.bar_color

        # ç¡®ä¿ratioåœ¨0-1èŒƒå›´å†…
        ratio = max(0, min(1, ratio))

        # è®¡ç®—åœ¨å“ªä¸¤ä¸ªé¢œè‰²ä¹‹é—´
        num_colors = len(self.gradient_colors)
        segment_size = 1.0 / (num_colors - 1)
        segment_index = int(ratio / segment_size)

        # é˜²æ­¢è¶Šç•Œ
        if segment_index >= num_colors - 1:
            return tuple(self.gradient_colors[-1])

        # è®¡ç®—åœ¨å½“å‰æ®µå†…çš„ä½ç½®
        local_ratio = (ratio - segment_index * segment_size) / segment_size

        # è·å–å½“å‰æ®µçš„èµ·å§‹å’Œç»“æŸé¢œè‰²
        start_color = self.gradient_colors[segment_index]
        end_color = self.gradient_colors[segment_index + 1]

        # çº¿æ€§æ’å€¼è®¡ç®—é¢œè‰²
        interpolated_color = []
        for i in range(3):  # BGRä¸‰ä¸ªé€šé“
            start_val = start_color[i]
            end_val = end_color[i]
            interpolated_val = int(start_val + (end_val - start_val) * local_ratio)
            interpolated_color.append(interpolated_val)

        return tuple(interpolated_color)

    def _get_default_character_path(self) -> str:
        """è·å–é»˜è®¤è§’è‰²è·¯å¾„ (ä½¿ç”¨ importlib.resources)"""
        try:
            # ç›´æ¥ä»'video_progress_pkg'åŒ…ä¸­å¯»æ‰¾èµ„æºæ–‡ä»¶è·¯å¾„
            # è¿™æ˜¯æœ€å¥å£®çš„æ–¹å¼ï¼Œæ— è®ºåŒ…å¦‚ä½•å®‰è£…éƒ½èƒ½å·¥ä½œ
            resource_path = files('video_progress_pkg').joinpath(
                'assets', 'characters', 'pikaqiu.gif')
            return str(resource_path)
        except (ImportError, AttributeError, FileNotFoundError):
            # å¦‚æœä¸Šé¢çš„æ–¹æ³•å› æŸç§åŸå› å¤±è´¥ï¼Œæä¾›ä¸€ä¸ªæœ€ç»ˆçš„å¤‡ç”¨æ–¹æ¡ˆ
            print("âš ï¸ æ— æ³•é€šè¿‡ importlib.resources å®šä½èµ„æºæ–‡ä»¶ï¼Œå°†ä½¿ç”¨ç›¸å¯¹è·¯å¾„ã€‚")
            return 'assets/characters/pikaqiu.gif'

    def _load_character(self) -> List[Tuple[np.ndarray, np.ndarray]]:
        """åŠ è½½è§’è‰²GIFçš„æ‰€æœ‰å¸§ï¼ŒåŒ…å«é€æ˜é®ç½©"""
        frames = []
        
        if not os.path.exists(self.character_path):
            print(f"âŒ è§’è‰²æ–‡ä»¶ä¸å­˜åœ¨: {self.character_path}")
            return [(self._create_default_character(), np.ones(self.character_size[::-1], dtype=np.uint8) * 255)]
        
        try:
            with Image.open(self.character_path) as gif:
                print(f"ğŸ® åŠ è½½è§’è‰²GIF: {gif.size}, å¸§æ•°: {gif.n_frames}")
                
                for frame_idx in range(gif.n_frames):
                    gif.seek(frame_idx)
                    frame_rgba = gif.convert('RGBA')
                    frame_resized = frame_rgba.resize(self.character_size, Image.Resampling.LANCZOS)
                    frame_array = np.array(frame_resized)
                    
                    # åˆ†ç¦»RGBå’ŒAlphaé€šé“
                    rgb_channels = frame_array[:, :, :3]
                    alpha_channel = frame_array[:, :, 3]
                    
                    # è½¬æ¢é¢œè‰²ç©ºé—´ RGB -> BGR
                    frame_bgr = cv2.cvtColor(rgb_channels, cv2.COLOR_RGB2BGR)
                    frames.append((frame_bgr, alpha_channel))
                    
        except Exception as e:
            print(f"âŒ åŠ è½½è§’è‰²GIFå‡ºé”™: {e}")
            default_char = self._create_default_character()
            default_mask = np.ones(self.character_size[::-1], dtype=np.uint8) * 255
            frames = [(default_char, default_mask)]
            
        return frames

    def _create_default_character(self) -> np.ndarray:
        """åˆ›å»ºé»˜è®¤è§’è‰²"""
        size = self.character_size[0]
        char = np.zeros((self.character_size[1], self.character_size[0], 3), dtype=np.uint8)
        
        center = (size // 2, self.character_size[1] // 2)
        radius = min(size, self.character_size[1]) // 3
        
        # ç»˜åˆ¶ç®€å•çš„åœ†å½¢è§’è‰²
        cv2.circle(char, center, radius, self.bar_color, -1)
        cv2.circle(char, (center[0] - radius//3, center[1] - radius//3), 3, (0, 0, 0), -1)
        cv2.circle(char, (center[0] + radius//3, center[1] - radius//3), 3, (0, 0, 0), -1)
        
        return char

    def _blend_with_alpha(self, background: np.ndarray, foreground: np.ndarray,
                         alpha_mask: np.ndarray, x: int, y: int) -> np.ndarray:
        """ä½¿ç”¨Alphaé€šé“æ··åˆå‰æ™¯å’ŒèƒŒæ™¯ï¼Œå¸¦è¾¹ç•Œæ£€æŸ¥"""
        result = background.copy()
        h, w = foreground.shape[:2]
        bg_h, bg_w = background.shape[:2]

        # ç¡®ä¿åæ ‡ä¸ºæ•´æ•°
        x, y = int(x), int(y)

        # è®¡ç®—æœ‰æ•ˆçš„æ··åˆåŒºåŸŸ
        src_x1 = max(0, -x)
        src_y1 = max(0, -y)
        src_x2 = min(w, bg_w - x)
        src_y2 = min(h, bg_h - y)

        dst_x1 = max(0, x)
        dst_y1 = max(0, y)
        dst_x2 = dst_x1 + (src_x2 - src_x1)
        dst_y2 = dst_y1 + (src_y2 - src_y1)

        # åªæœ‰å½“æœ‰æœ‰æ•ˆåŒºåŸŸæ—¶æ‰è¿›è¡Œæ··åˆ
        if src_x2 > src_x1 and src_y2 > src_y1:
            fg_region = foreground[src_y1:src_y2, src_x1:src_x2]
            bg_region = background[dst_y1:dst_y2, dst_x1:dst_x2]
            alpha_region = alpha_mask[src_y1:src_y2, src_x1:src_x2]

            alpha = alpha_region.astype(float) / 255.0
            alpha = np.expand_dims(alpha, axis=2)

            blended = fg_region * alpha + bg_region * (1 - alpha)
            result[dst_y1:dst_y2, dst_x1:dst_x2] = blended.astype(np.uint8)

        return result

    def _update_lightning_effects(self, char_x: int, char_y: int):
        """æ›´æ–°ç”µå…‰ç‰¹æ•ˆ"""
        if not self.enable_lightning:
            return

        # é™åˆ¶ç²’å­æ•°é‡ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
        if len(self.lightning_particles) > MAX_LIGHTNING_PARTICLES:
            self.lightning_particles = self.lightning_particles[-MAX_LIGHTNING_PARTICLES:]

        if self.frame_count % LIGHTNING_UPDATE_INTERVAL == 0 and np.random.random() > (1 - self.lightning_chance):
            lightning = {
                'x': char_x + np.random.randint(-20, 20),
                'y': char_y + np.random.randint(-10, 10),
                'life': 10,
                'intensity': np.random.randint(5, 15)
            }
            self.lightning_particles.append(lightning)

        self.lightning_particles = [p for p in self.lightning_particles if p['life'] > 0]
        for particle in self.lightning_particles:
            particle['life'] -= PARTICLE_LIFE_DECAY

    def _draw_lightning_effects(self, frame: np.ndarray):
        """ç»˜åˆ¶ç”µå…‰ç‰¹æ•ˆ"""
        frame_h, frame_w = frame.shape[:2]

        for particle in self.lightning_particles:
            # ç¡®ä¿èµ·å§‹ç‚¹åœ¨ç”»é¢å†…
            start_x = max(0, min(frame_w - 1, int(particle['x'])))
            start_y = max(0, min(frame_h - 1, int(particle['y'])))
            start_point = (start_x, start_y)

            for _ in range(3):  # ä½¿ç”¨ _ è¡¨ç¤ºä¸ä½¿ç”¨çš„å¾ªç¯å˜é‡
                end_x = start_x + np.random.randint(-15, 15)
                end_y = start_y + np.random.randint(-15, 15)

                # ç¡®ä¿ç»ˆç‚¹åœ¨ç”»é¢å†…
                end_x = max(0, min(frame_w - 1, end_x))
                end_y = max(0, min(frame_h - 1, end_y))
                end_point = (end_x, end_y)

                # ç¡®ä¿é¢œè‰²å€¼ä¸ºæ•´æ•°
                lightning_color = tuple(int(c) for c in self.lightning_color)

                cv2.line(frame, start_point, end_point, lightning_color, 2)
                cv2.line(frame, start_point, end_point, (255, 255, 255), 1)

    def _update_trail_particles(self, char_x: int, char_y: int):
        """æ›´æ–°å°¾è¿¹ç²’å­"""
        if not self.enable_particles:
            return

        # é™åˆ¶ç²’å­æ•°é‡ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
        if len(self.trail_particles) > MAX_TRAIL_PARTICLES:
            self.trail_particles = self.trail_particles[-MAX_TRAIL_PARTICLES:]

        if self.frame_count % 5 == 0:
            particle = {
                'x': char_x + self.character_size[0] // 2 + np.random.randint(-5, 5),
                'y': char_y + self.character_size[1] // 2 + np.random.randint(-5, 5),
                'life': self.particle_lifetime,
                'drift_x': np.random.randint(-2, 1),
                'drift_y': np.random.randint(-2, 2),
                'size': np.random.randint(2, 5)
            }
            self.trail_particles.append(particle)

        self.trail_particles = [p for p in self.trail_particles if p['life'] > 0]
        for particle in self.trail_particles:
            particle['life'] -= PARTICLE_LIFE_DECAY
            particle['x'] += particle['drift_x']
            particle['y'] += particle['drift_y']

    def _draw_trail_particles(self, frame: np.ndarray):
        """ç»˜åˆ¶å°¾è¿¹ç²’å­"""
        for particle in self.trail_particles:
            alpha = max(0.0, min(1.0, particle['life'] / self.particle_lifetime))

            # ç¡®ä¿é¢œè‰²å€¼ä¸ºæ•´æ•°ä¸”åœ¨æœ‰æ•ˆèŒƒå›´å†…
            color = tuple(max(0, min(255, int(c * alpha))) for c in self.particle_color)

            # ç¡®ä¿åæ ‡å’Œå¤§å°ä¸ºæ•´æ•°ä¸”åœ¨æœ‰æ•ˆèŒƒå›´å†…
            x = max(0, min(frame.shape[1] - 1, int(particle['x'])))
            y = max(0, min(frame.shape[0] - 1, int(particle['y'])))
            size = max(1, min(20, int(particle['size'])))

            cv2.circle(frame, (x, y), size, color, -1)

    def _draw_progress_bar(self, frame: np.ndarray, progress: float, width: int, height: int) -> np.ndarray:
        """ç»˜åˆ¶çµæ´»é…ç½®çš„è¿›åº¦æ¡"""
        frame_copy = frame.copy()
        self.frame_count += 1
        
        # è®¡ç®—è¿›åº¦æ¡ä½ç½®
        bar_width = width - 2 * self.margin
        
        if self.position == "bottom":
            bar_y = height - self.margin - self.bar_height
        else:
            bar_y = self.margin
        
        bar_x = self.margin
        
        # ç»˜åˆ¶è¾¹æ¡†
        if self.border_thickness > 0:
            cv2.rectangle(frame_copy,
                         (bar_x - self.border_thickness, bar_y - self.border_thickness),
                         (bar_x + bar_width + self.border_thickness, bar_y + self.bar_height + self.border_thickness),
                         self.border_color, self.border_thickness)

        # ç»˜åˆ¶è¿›åº¦æ¡èƒŒæ™¯
        cv2.rectangle(frame_copy, (bar_x, bar_y),
                     (bar_x + bar_width, bar_y + self.bar_height),
                     self.background_color, -1)
        
        # ç»˜åˆ¶è¿›åº¦
        progress_width = int(bar_width * progress)
        if progress_width > 0:
            if self.gradient_enabled and self.gradient_type == 'multi':
                # å¤šè‰²æ¸å˜è¿›åº¦æ¡ï¼ˆä½¿ç”¨é¢„è®¡ç®—çš„é¢œè‰²ï¼‰
                for i in range(progress_width):
                    ratio = i / progress_width if progress_width > 0 else 0
                    # ä½¿ç”¨é¢„è®¡ç®—çš„é¢œè‰²ç¼“å­˜
                    cache_index = int(ratio * 255)
                    color = self.gradient_color_cache.get(cache_index, self.bar_color)
                    cv2.line(frame_copy, (bar_x + i, bar_y),
                            (bar_x + i, bar_y + self.bar_height), color, 1)
            elif self.gradient_enabled:
                # å•è‰²æ¸å˜è¿›åº¦æ¡
                for i in range(progress_width):
                    ratio = i / progress_width if progress_width > 0 else 0
                    color = tuple(int(c * (0.6 + 0.4 * ratio)) for c in self.bar_color)
                    cv2.line(frame_copy, (bar_x + i, bar_y),
                            (bar_x + i, bar_y + self.bar_height), color, 1)
            else:
                # çº¯è‰²è¿›åº¦æ¡
                cv2.rectangle(frame_copy, (bar_x, bar_y),
                             (bar_x + progress_width, bar_y + self.bar_height),
                             self.bar_color, -1)
            
            # å‘å…‰æ•ˆæœ
            if self.glow_enabled and self.frame_count % 20 < 10:
                shine_x = bar_x + progress_width - 20
                if shine_x > bar_x:
                    cv2.line(frame_copy, (shine_x, bar_y), 
                            (shine_x, bar_y + self.bar_height), (255, 255, 255), 3)
        
        # è®¡ç®—è§’è‰²ä½ç½®
        base_char_x = bar_x + max(0, progress_width - self.character_size[0]) + self.character_offset_x
        base_char_y = bar_y + self.character_offset_y
        
        if self.position == "top":
            base_char_y = bar_y + self.bar_height + abs(self.character_offset_y)
        else:
            base_char_y = bar_y - self.character_size[1] + self.character_offset_y
        
        # è¾¹ç•Œæ£€æŸ¥
        char_x = max(0, min(base_char_x, width - self.character_size[0]))
        char_y = max(0, min(base_char_y, height - self.character_size[1]))
        
        # å¼¹è·³åŠ¨ç”»
        if self.enable_bounce:
            bounce = int(self.bounce_amplitude * abs(math.sin(self.frame_count * self.bounce_speed)))
            char_y -= bounce
        
        # æ›´æ–°ç‰¹æ•ˆ
        self._update_lightning_effects(char_x, char_y)
        self._update_trail_particles(char_x, char_y)
        
        # ç»˜åˆ¶ç‰¹æ•ˆ
        self._draw_lightning_effects(frame_copy)
        self._draw_trail_particles(frame_copy)
        
        # ç»˜åˆ¶è§’è‰²
        if self.total_frames > 0:
            current_frame_idx = (self.frame_count // self.animation_speed) % self.total_frames
            current_char, current_alpha = self.character_frames[current_frame_idx]
            
            try:
                frame_copy = self._blend_with_alpha(frame_copy, current_char, current_alpha, 
                                                  char_x, char_y)
            except Exception as e:
                print(f"ç»˜åˆ¶è§’è‰²æ—¶å‡ºé”™: {e}")
        
        # ç»˜åˆ¶è¿›åº¦æ–‡å­—
        progress_text = f"{progress*100:.1f}%"
        text_size_info = cv2.getTextSize(progress_text, cv2.FONT_HERSHEY_SIMPLEX, 
                                        self.text_size, 2)[0]
        
        # è®¡ç®—æ–‡å­—ä½ç½® - è·Ÿéšè¿›åº¦æ¡ç§»åŠ¨
        if self.text_position == 'follow':
            # æ–‡å­—è·Ÿéšè¿›åº¦æ¡å‰ç«¯
            progress_end_x = bar_x + progress_width
            text_x = max(bar_x, min(progress_end_x - text_size_info[0] // 2, 
                                   bar_x + bar_width - text_size_info[0]))
            text_x += self.text_offset_x
        elif self.text_position == 'left':
            text_x = bar_x + self.text_offset_x
        elif self.text_position == 'center':
            text_x = bar_x + (bar_width - text_size_info[0]) // 2 + self.text_offset_x
        else:  # right
            text_x = bar_x + bar_width - text_size_info[0] - self.text_offset_x
        
        text_y = bar_y + (self.bar_height + text_size_info[1]) // 2 + self.text_offset_y
        
        # æ–‡å­—æè¾¹æ•ˆæœ
        if self.text_outline:
            # ç»˜åˆ¶æè¾¹ï¼ˆå¤šæ–¹å‘åç§»ï¼‰
            outline_offsets = []
            thickness = self.text_outline_thickness
            for dx in range(-thickness, thickness + 1):
                for dy in range(-thickness, thickness + 1):
                    if dx != 0 or dy != 0:  # æ’é™¤ä¸­å¿ƒç‚¹
                        outline_offsets.append((dx, dy))

            # ç»˜åˆ¶æ‰€æœ‰æè¾¹
            for offset in outline_offsets:
                cv2.putText(frame_copy, progress_text,
                           (text_x + offset[0], text_y + offset[1]),
                           cv2.FONT_HERSHEY_SIMPLEX, self.text_size,
                           self.text_outline_color, 2)

        # ä¸»æ–‡å­—
        cv2.putText(frame_copy, progress_text, (text_x, text_y),
                   cv2.FONT_HERSHEY_SIMPLEX, self.text_size, self.text_color, 2)
        
        return frame_copy

    def process_video(self, input_video: str, output_video: Optional[str] = None) -> str:
        """
        å¤„ç†è§†é¢‘ï¼Œæ·»åŠ è¿›åº¦æ¡å¹¶ä¿ç•™éŸ³é¢‘
        
        Args:
            input_video: è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_video: è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤åœ¨è¾“å…¥æ–‡ä»¶åŒç›®å½•ç”Ÿæˆï¼‰
            
        Returns:
            str: è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Raises:
            FileNotFoundError: è¾“å…¥è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨
            ValueError: è§†é¢‘å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™
        """
        if not os.path.exists(input_video):
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {input_video}")

        # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        supported_formats = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']
        file_ext = os.path.splitext(input_video)[1].lower()
        if file_ext not in supported_formats:
            print(f"âš ï¸ è­¦å‘Š: æ–‡ä»¶æ ¼å¼ {file_ext} å¯èƒ½ä¸è¢«æ”¯æŒï¼Œæ”¯æŒçš„æ ¼å¼: {', '.join(supported_formats)}")

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(input_video)
        if file_size > 500 * 1024 * 1024:  # 500MB
            print(f"âš ï¸ è­¦å‘Š: è§†é¢‘æ–‡ä»¶è¾ƒå¤§ ({file_size / 1024 / 1024:.1f}MB)ï¼Œå¤„ç†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´å’Œå¤§é‡å†…å­˜")
        
        # æ”¹è¿›è¾“å‡ºè·¯å¾„å¤„ç†
        if output_video is None:
            # åœ¨åŸè§†é¢‘åŒç›®å½•ç”Ÿæˆï¼Œé¿å…ç¡¬ç¼–ç è·¯å¾„
            input_dir = os.path.dirname(input_video)
            if not input_dir:  # å¦‚æœè¾“å…¥è§†é¢‘åœ¨å½“å‰ç›®å½•
                input_dir = "."
            name, ext = os.path.splitext(os.path.basename(input_video))
            output_video = os.path.join(input_dir, f"{name}_progress{ext}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_video)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        
        # ä½¿ç”¨moviepyåŠ è½½è§†é¢‘å¹¶ä¿ç•™éŸ³é¢‘
        print("ğŸ¬ æ­£åœ¨åŠ è½½è§†é¢‘ï¼ˆåŒ…å«éŸ³é¢‘ï¼‰...")
        try:
            video_clip = VideoFileClip(input_video)
        except Exception as e:
            raise ValueError(f"æ— æ³•åŠ è½½è§†é¢‘æ–‡ä»¶ {input_video}: {e}")

        fps = video_clip.fps
        width, height = video_clip.size
        duration = video_clip.duration

        # æ£€æŸ¥è§†é¢‘åŸºæœ¬ä¿¡æ¯çš„æœ‰æ•ˆæ€§
        if fps <= 0 or width <= 0 or height <= 0 or duration <= 0:
            video_clip.close()
            raise ValueError(f"è§†é¢‘æ–‡ä»¶ä¿¡æ¯æ— æ•ˆ: fps={fps}, size={width}x{height}, duration={duration}")

        total_frames = int(fps * duration)

        print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯:")
        print(f"  åˆ†è¾¨ç‡: {width}x{height}")
        print(f"  å¸§ç‡: {fps:.1f} FPS")
        print(f"  æ—¶é•¿: {duration:.2f} ç§’")
        print(f"  æ€»å¸§æ•°: {total_frames}")
        print(f"  è§’è‰²åŠ¨ç”»å¸§æ•°: {self.total_frames}")
        print(f"  éŸ³é¢‘: {'âœ… åŒ…å«' if video_clip.audio else 'âŒ æ— éŸ³é¢‘'}")

        print("ğŸ® æ­£åœ¨å¤„ç†è§†é¢‘å¸§...")

        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = tqdm(total=total_frames, desc="å¤„ç†è§†é¢‘å¸§", unit="å¸§",
                           bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')

        processed_frames = 0

        def process_frame(get_frame, t):
            """å¤„ç†å•ä¸ªå¸§çš„å‡½æ•°"""
            nonlocal processed_frames

            frame = get_frame(t)
            # MoviePy 2.x ç›´æ¥è¿”å›uint8æ ¼å¼(0-255)ï¼Œæ— éœ€ä¹˜ä»¥255
            if frame.dtype == np.float64 or frame.dtype == np.float32:
                # å¦‚æœæ˜¯æµ®ç‚¹æ•°(0-1)ï¼Œè½¬æ¢ä¸ºuint8
                frame_bgr = cv2.cvtColor((frame * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)
            else:
                # å¦‚æœå·²ç»æ˜¯uint8(0-255)ï¼Œç›´æ¥è½¬æ¢
                frame_bgr = cv2.cvtColor(frame.astype(np.uint8), cv2.COLOR_RGB2BGR)

            # è®¡ç®—è¿›åº¦
            progress = t / duration if duration > 0 else 0

            # æ·»åŠ è¿›åº¦æ¡
            frame_with_progress = self._draw_progress_bar(frame_bgr, progress, width, height)

            # è½¬æ¢å›RGBç»™moviepyï¼ŒMoviePy 2.x æœŸæœ›uint8æ ¼å¼
            frame_rgb = cv2.cvtColor(frame_with_progress, cv2.COLOR_BGR2RGB)

            # æ›´æ–°è¿›åº¦æ¡
            processed_frames += 1
            progress_bar.update(1)

            return frame_rgb.astype(np.uint8)

        # åˆ›å»ºæ–°çš„è§†é¢‘å‰ªè¾‘ï¼Œåº”ç”¨è¿›åº¦æ¡å¤„ç† (MoviePy 2.x API)
        processed_clip = video_clip.transform(process_frame)

        # ä¿ç•™åŸå§‹éŸ³é¢‘ (MoviePy 2.x API)
        if video_clip.audio:
            processed_clip = processed_clip.with_audio(video_clip.audio)
            print("ğŸ”Š ä¿ç•™åŸå§‹éŸ³é¢‘")

        print("ğŸ’¾ æ­£åœ¨å†™å…¥æœ€ç»ˆè§†é¢‘...")

        # å†™å…¥è§†é¢‘ï¼Œå¹¶æŒ‡å®šé«˜è´¨é‡å‚æ•° (MoviePy 2.x API)
        processed_clip.write_videofile(
            output_video,
            fps=fps,
            codec='libx264',      # ä½¿ç”¨é«˜è´¨é‡å’Œå…¼å®¹æ€§å¥½çš„H.264ç¼–ç å™¨
            bitrate='10000k',     # è®¾ç½®ä¸€ä¸ªè¾ƒé«˜çš„ç ç‡ (ä¾‹å¦‚ 10000 kbps)ã€‚åŸè§†é¢‘ç ç‡è¶Šé«˜ï¼Œè¿™é‡Œå¯ä»¥è®¾å¾—è¶Šé«˜ã€‚
            preset='medium',      # 'slow'æˆ–'veryslow'å¯ä»¥è·å¾—æ›´é«˜å‹ç¼©ç‡ï¼ˆåŒç­‰ç ç‡ä¸‹è´¨é‡æ›´å¥½ï¼‰ï¼Œä½†è€—æ—¶æ›´é•¿ã€‚'medium'æ˜¯å¾ˆå¥½çš„å¹³è¡¡ç‚¹ã€‚
            threads=4,            # ä½¿ç”¨å¤šä¸ªCPUæ ¸å¿ƒæ¥åŠ é€Ÿç¼–ç 
            logger=None           # MoviePy 2.x: ä½¿ç”¨loggerä»£æ›¿verboseå‚æ•°
        )

        # å…³é—­è¿›åº¦æ¡
        progress_bar.close()

        # æ¸…ç†èµ„æº
        processed_clip.close()
        video_clip.close()

        print(f"ğŸ‰ è§†é¢‘å¤„ç†å®Œæˆ! è¾“å‡ºæ–‡ä»¶: {output_video}")

        return output_video

    def _get_gradient_color(self, ratio):
        """æ ¹æ®æ¯”ä¾‹è·å–å¤šè‰²æ¸å˜ä¸­çš„é¢œè‰²"""
        if not self.gradient_colors or len(self.gradient_colors) < 2:
            return self.bar_color

        # ç¡®ä¿ratioåœ¨0-1èŒƒå›´å†…
        ratio = max(0, min(1, ratio))

        # è®¡ç®—åœ¨å“ªä¸¤ä¸ªé¢œè‰²ä¹‹é—´
        num_colors = len(self.gradient_colors)
        segment_size = 1.0 / (num_colors - 1)
        segment_index = int(ratio / segment_size)

        # é˜²æ­¢è¶Šç•Œ
        if segment_index >= num_colors - 1:
            return tuple(self.gradient_colors[-1])

        # è®¡ç®—åœ¨å½“å‰æ®µå†…çš„ä½ç½®
        local_ratio = (ratio - segment_index * segment_size) / segment_size

        # è·å–å½“å‰æ®µçš„èµ·å§‹å’Œç»“æŸé¢œè‰²
        start_color = self.gradient_colors[segment_index]
        end_color = self.gradient_colors[segment_index + 1]

        # çº¿æ€§æ’å€¼è®¡ç®—é¢œè‰²
        interpolated_color = []
        for i in range(3):  # BGRä¸‰ä¸ªé€šé“
            start_val = start_color[i]
            end_val = end_color[i]
            interpolated_val = int(start_val + (end_val - start_val) * local_ratio)
            interpolated_color.append(interpolated_val)

        return tuple(interpolated_color)


def load_config(config_path: str) -> Dict[str, Any]:
    """ä»JSONæ–‡ä»¶åŠ è½½é…ç½®"""
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def save_default_config(config_path: str):
    """ä¿å­˜é»˜è®¤é…ç½®åˆ°JSONæ–‡ä»¶"""
    default_config = {
        "input_video": "assets/samples/sample_video.mp4",
        "output_video": "",
        
        "bar_height": 40,
        "bar_color": [0, 255, 255],
        "background_color": [50, 50, 50],
        "position": "bottom",
        "margin": 25,
        
        "character_path": "assets/characters/pikaqiu.gif",
        "character_size": [60, 60],
        "character_offset_x": 0,
        "character_offset_y": -5,
        
        "enable_bounce": True,
        "bounce_amplitude": 8,
        "bounce_speed": 0.2,
        "animation_speed": 3,
        
        "enable_lightning": True,
        "lightning_chance": 0.3,
        "lightning_color": [0, 255, 255],
        
        "enable_particles": True,
        "particle_color": [0, 255, 255],
        "particle_lifetime": 60,
        
        "text_color": [0, 255, 255],
        "text_size": 0.8,
        "text_position": "follow",
        "text_offset_x": 0,
        "text_offset_y": -10,
        
        "border_thickness": 3,
        "border_color": [255, 255, 255],
        "gradient_enabled": True,
        "glow_enabled": True
    }
    
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(default_config, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ é»˜è®¤é…ç½®å·²ä¿å­˜åˆ°: {config_path}")
